{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Real images source found, name:CelebA_Original\n",
      "[INFO]: 4 different generator sources found. Names:\n",
      "cifar-10\n",
      "diffusionStyleGAN2\n",
      "diffusionVAE\n",
      "guidedDiffusion_IP\n"
     ]
    }
   ],
   "source": [
    "from framework.Platform import PlatformManager\n",
    "from framework.Configs import PlatformConfig, EvalConfig\n",
    "import os\n",
    "\n",
    "\n",
    "eval_cfg = EvalConfig(\n",
    "    inception_score=True,\n",
    "    fid=True,\n",
    "    kid=True,\n",
    "    prc=True,\n",
    "    ppl=False,\n",
    ")\n",
    "\n",
    "platform_cfg = PlatformConfig(\n",
    "    verbose=True,\n",
    "    cuda=True,\n",
    "    save_cpu_ram=False,\n",
    "    compare_real_to_real=True\n",
    ")\n",
    "\n",
    "platform_manager = PlatformManager(real_images_path=os.path.join(os.getcwd(), \"original_64\"),\n",
    "                                   eval_config=eval_cfg,\n",
    "                                   platform_config=platform_cfg)\n",
    "\n",
    "#platform_manager.calc_metrics()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Real images source found, name:CelebA_Original\n",
      "[INFO]: 1 different generator sources found. Names:\n",
      "original_64\n",
      "[INFO]: Comparison real-to-real (True)\n",
      "[START]: Calculating Metrics for original_64\n",
      "[INFO]: Start Calculation IS, Source = original_64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased']\n",
      "Extracting features from input1\n",
      "Processing samples                                                               \n",
      "Inception Score: 3.5856323974726556 ± 0.020385455507128\n",
      "Creating feature extractor \"inception-v3-compat\" with features ['2048']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: IS finished\n",
      "[INFO]: Start Calculation FID, Source = original_64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features from input1\n",
      "Processing samples                                                               \n",
      "Extracting features from input2\n",
      "Processing samples                                                               \n",
      "Frechet Inception Distance: -5.684341886080802e-14\n",
      "Kernel Inception Distance: -1.4059582082075472e-05 ± 9.778459226345613e-05      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: FID finished\n",
      "[INFO]: Start Calculation KID, Source = original_64\n",
      "[INFO]: KID finished\n",
      "[INFO]: Start Calculation Improved PRC, Source = original_64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"vgg16\" with features ['fc2_relu']\n",
      "Extracting features from input1\n",
      "Processing samples                                                             \n",
      "Extracting features from input2\n",
      "Processing samples                                                             \n",
      "Precision: 0.7388799786567688\n",
      "Recall: 0.7351599931716919\n",
      "F-score: 0.7370152919126179\n",
      "Creating feature extractor \"inception-v3-compat\" with features ['logits_unbiased']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Improved PRC finished\n",
      "[FINISHED]: Calculating Metrics for original_64\n",
      "{'Inception Score Mean': 3.5856323974726556, 'Inception Score Std': 0.020385455507128, 'Frechet Inception Distance': -5.684341886080802e-14, 'Kernel Inception Distance Mean': -1.4059582082075472e-05, 'Kernel Inception Distance Std': 9.778459226345613e-05, 'Precision': 0.7388799786567688, 'Recall': 0.7351599931716919, 'F1 Score': 0.7370152919126179}\n",
      "[START]: Calculating Metrics for CelebA_Original\n",
      "[INFO]: Start Calculation IS, Source = CelebA_Original\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features from input1\n",
      "Processing samples                                                               \n",
      "Inception Score: 3.5856323974726556 ± 0.020385455507128\n",
      "Creating feature extractor \"inception-v3-compat\" with features ['2048']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: IS finished\n",
      "[INFO]: Start Calculation FID, Source = CelebA_Original\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features from input1\n",
      "Processing samples                                                               \n",
      "Extracting features from input2\n",
      "Processing samples                                                               \n",
      "Frechet Inception Distance: -5.684341886080802e-14\n",
      "Kernel Inception Distance: -1.4059582082075472e-05 ± 9.778459226345613e-05      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: FID finished\n",
      "[INFO]: Start Calculation KID, Source = CelebA_Original\n",
      "[INFO]: KID finished\n",
      "[INFO]: Start Calculation Improved PRC, Source = CelebA_Original\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"vgg16\" with features ['fc2_relu']\n",
      "Extracting features from input1\n",
      "Processing samples                                                             \n",
      "Extracting features from input2\n",
      "Processing samples                                                             \n",
      "Precision: 0.7380800247192383\n",
      "Recall: 0.7356799840927124\n",
      "F-score: 0.7368780501546134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Improved PRC finished\n",
      "[FINISHED]: Calculating Metrics for CelebA_Original\n",
      "{'Inception Score Mean': 3.5856323974726556, 'Inception Score Std': 0.020385455507128, 'Frechet Inception Distance': -5.684341886080802e-14, 'Kernel Inception Distance Mean': -1.4059582082075472e-05, 'Kernel Inception Distance Std': 9.778459226345613e-05, 'Precision': 0.7380800247192383, 'Recall': 0.7356799840927124, 'F1 Score': 0.7368780501546134}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 27\u001b[0m\n\u001b[0;32m     21\u001b[0m platform_manager \u001b[39m=\u001b[39m PlatformManager(real_images_path\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mgetcwd(), \u001b[39m\"\u001b[39m\u001b[39moriginal_64\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m     22\u001b[0m                                    generated_images_path\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mgetcwd(), \u001b[39m\"\u001b[39m\u001b[39mtmp\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m     23\u001b[0m                                    eval_config\u001b[39m=\u001b[39meval_cfg,\n\u001b[0;32m     24\u001b[0m                                    platform_config\u001b[39m=\u001b[39mplatform_cfg)\n\u001b[0;32m     26\u001b[0m result_dict \u001b[39m=\u001b[39m platform_manager\u001b[39m.\u001b[39mcalc_metrics()\n\u001b[1;32m---> 27\u001b[0m result_dict\u001b[39m.\u001b[39;49mprint()\n",
      "File \u001b[1;32md:\\Dokumente\\SoftwareDev\\MasterThesis\\GIM-evaluation\\framework\\Platform.py:32\u001b[0m, in \u001b[0;36mResultDict.print\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     29\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m    Custom print function\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     \u001b[39mfor\u001b[39;00m generator, sub_dict \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata:\n\u001b[0;32m     33\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGenerator Name:[\u001b[39m\u001b[39m{\u001b[39;00mgenerator\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m         \u001b[39mfor\u001b[39;00m metric, score \u001b[39min\u001b[39;00m sub_dict:\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from framework.Platform import PlatformManager\n",
    "from framework.Configs import PlatformConfig, EvalConfig\n",
    "import os\n",
    "\n",
    "\n",
    "eval_cfg = EvalConfig(\n",
    "    inception_score=True,\n",
    "    fid=True,\n",
    "    kid=True,\n",
    "    prc=True,\n",
    "    ppl=False,\n",
    ")\n",
    "\n",
    "platform_cfg = PlatformConfig(\n",
    "    verbose=True,\n",
    "    cuda=True,\n",
    "    save_cpu_ram=False,\n",
    "    compare_real_to_real=True\n",
    ")\n",
    "\n",
    "platform_manager = PlatformManager(real_images_path=os.path.join(os.getcwd(), \"original_64\"),\n",
    "                                   generated_images_path=os.path.join(os.getcwd(), \"tmp\"),\n",
    "                                   eval_config=eval_cfg,\n",
    "                                   platform_config=platform_cfg)\n",
    "\n",
    "result_dict = platform_manager.calc_metrics()\n",
    "result_dict.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "Generator Name: original_64\n",
      "------------------------------------\n",
      "Inception Score Mean: 3.586\n",
      "Inception Score Std: 0.02\n",
      "Frechet Inception Distance: -0.0\n",
      "Kernel Inception Distance Mean: -0.0\n",
      "Kernel Inception Distance Std: 0.0\n",
      "Precision: 0.739\n",
      "Recall: 0.735\n",
      "F1 Score: 0.737\n",
      "------------------------------------\n",
      "Generator Name: CelebA_Original\n",
      "------------------------------------\n",
      "Inception Score Mean: 3.586\n",
      "Inception Score Std: 0.02\n",
      "Frechet Inception Distance: -0.0\n",
      "Kernel Inception Distance Mean: -0.0\n",
      "Kernel Inception Distance Std: 0.0\n",
      "Precision: 0.738\n",
      "Recall: 0.736\n",
      "F1 Score: 0.737\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for generator in result_dict.data:\n",
    "    print(\"------------------------------------\")\n",
    "    print(f\"Generator Name: {generator}\")\n",
    "    print(\"------------------------------------\")\n",
    "    for metric in result_dict.data[generator]:\n",
    "        print(f\"{metric}: {np.round(result_dict.data[generator][metric], 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "At least one metric must be specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available())\n\u001b[1;32m----> 6\u001b[0m metrics_dict \u001b[39m=\u001b[39m torch_fidelity\u001b[39m.\u001b[39;49mcalculate_metrics(\n\u001b[0;32m      7\u001b[0m     input1\u001b[39m=\u001b[39;49mplatform_manager\u001b[39m.\u001b[39;49mhelper\u001b[39m.\u001b[39;49mreal_images_src\u001b[39m.\u001b[39;49mget_dataset(), \n\u001b[0;32m      8\u001b[0m     input2\u001b[39m=\u001b[39;49mplatform_manager\u001b[39m.\u001b[39;49mhelper\u001b[39m.\u001b[39;49mget_generator_src(\u001b[39m\"\u001b[39;49m\u001b[39mguidedDiffusion_IP\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mget_dataset(), \n\u001b[0;32m      9\u001b[0m     cuda\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \n\u001b[0;32m     10\u001b[0m     isc\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \n\u001b[0;32m     11\u001b[0m     fid\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \n\u001b[0;32m     12\u001b[0m     kid\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \n\u001b[0;32m     13\u001b[0m     prc\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \n\u001b[0;32m     14\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     15\u001b[0m     save_cpu_ram\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     16\u001b[0m )\n",
      "File \u001b[1;32md:\\dokumente\\softwaredev\\masterthesis\\gim-evaluation\\src\\torch-fidelity\\torch_fidelity\\metrics.py:322\u001b[0m, in \u001b[0;36mcalculate_metrics\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m have_default_fe_vgg \u001b[39m=\u001b[39m have_prc\n\u001b[0;32m    320\u001b[0m \u001b[39mif\u001b[39;00m fe_name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m (have_default_fe_inception \u001b[39mand\u001b[39;00m have_default_fe_vgg):\n\u001b[0;32m    321\u001b[0m     \u001b[39m# using the same non-default feature extractor for all metrics except ppl, or using just one default extractor\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m     \u001b[39mreturn\u001b[39;00m calculate_metrics_one_feature_extractor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    324\u001b[0m out \u001b[39m=\u001b[39m {}\n\u001b[0;32m    325\u001b[0m kwargs_subset \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\dokumente\\softwaredev\\masterthesis\\gim-evaluation\\src\\torch-fidelity\\torch_fidelity\\metrics.py:31\u001b[0m, in \u001b[0;36mcalculate_metrics_one_feature_extractor\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     28\u001b[0m need_input1 \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     29\u001b[0m need_input2 \u001b[39m=\u001b[39m have_binary\n\u001b[1;32m---> 31\u001b[0m vassert(have_any, \u001b[39m'\u001b[39;49m\u001b[39mAt least one metric must be specified\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     32\u001b[0m vassert(input1 \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m need_input1, \u001b[39m'\u001b[39m\u001b[39mFirst input is required for all metrics\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     33\u001b[0m vassert(input2 \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m need_input2, \u001b[39m'\u001b[39m\u001b[39mSecond input is required for binary metrics\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32md:\\dokumente\\softwaredev\\masterthesis\\gim-evaluation\\src\\torch-fidelity\\torch_fidelity\\helpers.py:11\u001b[0m, in \u001b[0;36mvassert\u001b[1;34m(truecond, message)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvassert\u001b[39m(truecond, message):\n\u001b[0;32m     10\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m truecond:\n\u001b[1;32m---> 11\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: At least one metric must be specified"
     ]
    }
   ],
   "source": [
    "import torch_fidelity\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "metrics_dict = torch_fidelity.calculate_metrics(\n",
    "    input1=platform_manager.helper.real_images_src.get_dataset(), \n",
    "    input2=platform_manager.helper.get_generator_src(\"guidedDiffusion_IP\").get_dataset(), \n",
    "    cuda=True, \n",
    "    isc=False, \n",
    "    fid=False, \n",
    "    kid=False, \n",
    "    prc=False, \n",
    "    verbose=True,\n",
    "    save_cpu_ram=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"vgg16\" with features ['fc2_relu']\n",
      "Extracting features from input1\n",
      "Processing samples                                                             \n",
      "Extracting features from input2\n",
      "Processing samples                                                             \n",
      "Precision: 0.6168400049209595\n",
      "Recall: 0.3585200011730194\n",
      "F-score: 0.4534725186722886\n"
     ]
    }
   ],
   "source": [
    "metrics_dict = torch_fidelity.calculate_metrics(\n",
    "    input1=platform_manager.helper.real_images_src.get_dataset(), \n",
    "    input2=platform_manager.helper.get_generator_src(\"diffusionStyleGAN2\").get_dataset(), \n",
    "    cuda=True, \n",
    "    isc=False, \n",
    "    fid=False, \n",
    "    kid=False, \n",
    "    prc=True, \n",
    "    verbose=True,\n",
    "    save_cpu_ram=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 64, 64, 3) size array saved into celeba64_train.npz\n"
     ]
    }
   ],
   "source": [
    "from framework.util import img_to_64\n",
    "\n",
    "img_to_64(\"D:\\Dokumente\\SoftwareDev\\MasterThesis\\GIM-evaluation\\cifar-10\\\\train\\\\train\\\\\",\n",
    "             \"D:\\Dokumente\\SoftwareDev\\MasterThesis\\GIM-evaluation\\cifar-10\\\\64res\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from 3rd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GIM-Eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
