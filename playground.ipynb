{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real images found, name:CelebA_Original\n",
      "3 different generator sources found. Names:\n",
      "diffusionStyleGAN2\n",
      "diffusionVAE\n",
      "guidedDiffusion_IP\n",
      "[START]: Calculating Metrics for diffusionStyleGAN2\n",
      "50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"vgg16\" with features ['fc2_relu']\n",
      "Extracting features from input1\n",
      "                                                                  \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m\n\u001b[0;32m     10\u001b[0m platform_cfg \u001b[39m=\u001b[39m PlatformConfig(\n\u001b[0;32m     11\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     12\u001b[0m     cuda\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     15\u001b[0m platform_manager \u001b[39m=\u001b[39m PlatformManager(real_images_path\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mgetcwd(), \u001b[39m\"\u001b[39m\u001b[39moriginal_64\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m     16\u001b[0m                                    eval_config\u001b[39m=\u001b[39meval_cfg,\n\u001b[0;32m     17\u001b[0m                                    platform_config\u001b[39m=\u001b[39mplatform_cfg)\n\u001b[1;32m---> 19\u001b[0m platform_manager\u001b[39m.\u001b[39;49mcalc_metrics()\n",
      "File \u001b[1;32md:\\Dokumente\\SoftwareDev\\MasterThesis\\GIM-evaluation\\framework\\Platform.py:110\u001b[0m, in \u001b[0;36mPlatformManager.calc_metrics\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m     name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mImproved Precision Recall\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m     metric_prc \u001b[39m=\u001b[39m PRC(name\u001b[39m=\u001b[39mname, eval_config\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_cfg, platform_config\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplatform_cfg, real_img\u001b[39m=\u001b[39mreal_img, generated_img\u001b[39m=\u001b[39mgenerated_img)\n\u001b[1;32m--> 110\u001b[0m     precision, recall, f1 \u001b[39m=\u001b[39m metric_prc\u001b[39m.\u001b[39;49mcalculate()\n\u001b[0;32m    111\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_dict\u001b[39m.\u001b[39mupdate({\u001b[39m\"\u001b[39m\u001b[39mPrecision\u001b[39m\u001b[39m\"\u001b[39m : precision, \u001b[39m\"\u001b[39m\u001b[39mRecall\u001b[39m\u001b[39m\"\u001b[39m : recall, \u001b[39m\"\u001b[39m\u001b[39mF1 Score\u001b[39m\u001b[39m\"\u001b[39m : f1})\n\u001b[0;32m    113\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[FINISHED]: Calculating Metrics for \u001b[39m\u001b[39m{\u001b[39;00mgenerator_src\u001b[39m.\u001b[39msource_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Dokumente\\SoftwareDev\\MasterThesis\\GIM-evaluation\\metrics\\prc_metric.py:35\u001b[0m, in \u001b[0;36mPRC.calculate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalculate\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]:\n\u001b[0;32m     34\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreal_img_downsampled) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerated_img), \u001b[39m\"\u001b[39m\u001b[39mDifferent sample sizes of real and generated images!\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 35\u001b[0m     metric_dict \u001b[39m=\u001b[39m torch_fidelity\u001b[39m.\u001b[39;49mcalculate_metrics(\n\u001b[0;32m     36\u001b[0m         input1\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreal_img_downsampled,\n\u001b[0;32m     37\u001b[0m         input2\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerated_img,\n\u001b[0;32m     38\u001b[0m         cuda\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mplatform_config\u001b[39m.\u001b[39;49mcuda,\n\u001b[0;32m     39\u001b[0m         prc\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     40\u001b[0m         prc_neighborhood\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meval_config\u001b[39m.\u001b[39;49mprc_neighborhood,\n\u001b[0;32m     41\u001b[0m         prc_batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meval_config\u001b[39m.\u001b[39;49mprc_batch_size,\n\u001b[0;32m     42\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mplatform_config\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m     43\u001b[0m         save_cpu_ram\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mplatform_config\u001b[39m.\u001b[39;49msave_cpu_ram,\n\u001b[0;32m     44\u001b[0m     )\n\u001b[0;32m     45\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m     46\u001b[0m         metric_dict[KEY_METRIC_PRECISION],\n\u001b[0;32m     47\u001b[0m         metric_dict[KEY_METRIC_RECALL],\n\u001b[0;32m     48\u001b[0m         metric_dict[KEY_METRIC_F_SCORE],\n\u001b[0;32m     49\u001b[0m     )\n",
      "File \u001b[1;32md:\\dokumente\\softwaredev\\masterthesis\\gim-evaluation\\src\\torch-fidelity\\torch_fidelity\\metrics.py:322\u001b[0m, in \u001b[0;36mcalculate_metrics\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m have_default_fe_vgg \u001b[39m=\u001b[39m have_prc\n\u001b[0;32m    320\u001b[0m \u001b[39mif\u001b[39;00m fe_name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m (have_default_fe_inception \u001b[39mand\u001b[39;00m have_default_fe_vgg):\n\u001b[0;32m    321\u001b[0m     \u001b[39m# using the same non-default feature extractor for all metrics except ppl, or using just one default extractor\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m     \u001b[39mreturn\u001b[39;00m calculate_metrics_one_feature_extractor(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    324\u001b[0m out \u001b[39m=\u001b[39m {}\n\u001b[0;32m    325\u001b[0m kwargs_subset \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\dokumente\\softwaredev\\masterthesis\\gim-evaluation\\src\\torch-fidelity\\torch_fidelity\\metrics.py:67\u001b[0m, in \u001b[0;36mcalculate_metrics_one_feature_extractor\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[39mreturn\u001b[39;00m metrics\n\u001b[0;32m     66\u001b[0m vprint(verbose, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mExtracting features from input1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 67\u001b[0m featuresdict_1 \u001b[39m=\u001b[39m extract_featuresdict_from_input_id_cached(\u001b[39m1\u001b[39m, feat_extractor, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     68\u001b[0m featuresdict_2 \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[39mif\u001b[39;00m input2 \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\dokumente\\softwaredev\\masterthesis\\gim-evaluation\\src\\torch-fidelity\\torch_fidelity\\utils.py:407\u001b[0m, in \u001b[0;36mextract_featuresdict_from_input_id_cached\u001b[1;34m(input_id, feat_extractor, **kwargs)\u001b[0m\n\u001b[0;32m    400\u001b[0m     featuresdict \u001b[39m=\u001b[39m cache_lookup_group_recompute_all_on_any_miss(\n\u001b[0;32m    401\u001b[0m         cached_filename_prefix,\n\u001b[0;32m    402\u001b[0m         feat_extractor\u001b[39m.\u001b[39mget_requested_features_list(),\n\u001b[0;32m    403\u001b[0m         fn_recompute,\n\u001b[0;32m    404\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    405\u001b[0m     )\n\u001b[0;32m    406\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 407\u001b[0m     featuresdict \u001b[39m=\u001b[39m fn_recompute()\n\u001b[0;32m    408\u001b[0m \u001b[39mreturn\u001b[39;00m featuresdict\n",
      "File \u001b[1;32md:\\dokumente\\softwaredev\\masterthesis\\gim-evaluation\\src\\torch-fidelity\\torch_fidelity\\utils.py:395\u001b[0m, in \u001b[0;36mextract_featuresdict_from_input_id_cached.<locals>.fn_recompute\u001b[1;34m()\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfn_recompute\u001b[39m():\n\u001b[1;32m--> 395\u001b[0m     \u001b[39mreturn\u001b[39;00m extract_featuresdict_from_input_id(input_id, feat_extractor, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\dokumente\\softwaredev\\masterthesis\\gim-evaluation\\src\\torch-fidelity\\torch_fidelity\\utils.py:380\u001b[0m, in \u001b[0;36mextract_featuresdict_from_input_id\u001b[1;34m(input_id, feat_extractor, **kwargs)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39minput\u001b[39m, Dataset):\n\u001b[0;32m    379\u001b[0m     save_cpu_ram \u001b[39m=\u001b[39m get_kwarg(\u001b[39m'\u001b[39m\u001b[39msave_cpu_ram\u001b[39m\u001b[39m'\u001b[39m, kwargs)\n\u001b[1;32m--> 380\u001b[0m     featuresdict \u001b[39m=\u001b[39m get_featuresdict_from_dataset(\u001b[39minput\u001b[39;49m, feat_extractor, batch_size, cuda, save_cpu_ram, verbose)\n\u001b[0;32m    381\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    382\u001b[0m     input_desc \u001b[39m=\u001b[39m prepare_input_descriptor_from_input_id(input_id, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\dokumente\\softwaredev\\masterthesis\\gim-evaluation\\src\\torch-fidelity\\torch_fidelity\\utils.py:131\u001b[0m, in \u001b[0;36mget_featuresdict_from_dataset\u001b[1;34m(input, feat_extractor, batch_size, cuda, save_cpu_ram, verbose)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[39mif\u001b[39;00m cuda:\n\u001b[0;32m    129\u001b[0m     batch \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39mcuda(non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 131\u001b[0m features \u001b[39m=\u001b[39m feat_extractor(batch)\n\u001b[0;32m    132\u001b[0m featuresdict \u001b[39m=\u001b[39m feat_extractor\u001b[39m.\u001b[39mconvert_features_tuple_to_dict(features)\n\u001b[0;32m    133\u001b[0m featuresdict \u001b[39m=\u001b[39m {k: [v\u001b[39m.\u001b[39mcpu()] \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m featuresdict\u001b[39m.\u001b[39mitems()}\n",
      "File \u001b[1;32md:\\Users\\qrno9\\miniconda3\\envs\\GIM-Eval\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\dokumente\\softwaredev\\masterthesis\\gim-evaluation\\src\\torch-fidelity\\torch_fidelity\\feature_extractor_vgg16.py:87\u001b[0m, in \u001b[0;36mFeatureExtractorVGG16.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     79\u001b[0m x \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mnormalize(\n\u001b[0;32m     80\u001b[0m     x,\n\u001b[0;32m     81\u001b[0m     (\u001b[39m255\u001b[39m \u001b[39m*\u001b[39m \u001b[39m0.485\u001b[39m, \u001b[39m255\u001b[39m \u001b[39m*\u001b[39m \u001b[39m0.456\u001b[39m, \u001b[39m255\u001b[39m \u001b[39m*\u001b[39m \u001b[39m0.406\u001b[39m),\n\u001b[0;32m     82\u001b[0m     (\u001b[39m255\u001b[39m \u001b[39m*\u001b[39m \u001b[39m0.229\u001b[39m, \u001b[39m255\u001b[39m \u001b[39m*\u001b[39m \u001b[39m0.224\u001b[39m, \u001b[39m255\u001b[39m \u001b[39m*\u001b[39m \u001b[39m0.225\u001b[39m),\n\u001b[0;32m     83\u001b[0m     inplace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     84\u001b[0m )\n\u001b[0;32m     85\u001b[0m \u001b[39m# N x 3 x 224 x 224\u001b[39;00m\n\u001b[1;32m---> 87\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)\n\u001b[0;32m     89\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mfc2\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m remaining_features:\n\u001b[0;32m     90\u001b[0m     features[\u001b[39m'\u001b[39m\u001b[39mfc2\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(torch\u001b[39m.\u001b[39mfloat32)\n",
      "File \u001b[1;32md:\\Users\\qrno9\\miniconda3\\envs\\GIM-Eval\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Users\\qrno9\\miniconda3\\envs\\GIM-Eval\\lib\\site-packages\\torchvision\\models\\vgg.py:66\u001b[0m, in \u001b[0;36mVGG.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m---> 66\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures(x)\n\u001b[0;32m     67\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n\u001b[0;32m     68\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32md:\\Users\\qrno9\\miniconda3\\envs\\GIM-Eval\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Users\\qrno9\\miniconda3\\envs\\GIM-Eval\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32md:\\Users\\qrno9\\miniconda3\\envs\\GIM-Eval\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Users\\qrno9\\miniconda3\\envs\\GIM-Eval\\lib\\site-packages\\torch\\nn\\modules\\conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[1;32md:\\Users\\qrno9\\miniconda3\\envs\\GIM-Eval\\lib\\site-packages\\torch\\nn\\modules\\conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[0;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[0;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[0;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from framework.Platform import PlatformManager\n",
    "from framework.Configs import PlatformConfig, EvalConfig\n",
    "import os\n",
    "\n",
    "\n",
    "eval_cfg = EvalConfig(\n",
    "    inception_score=True,\n",
    "    fid=True,\n",
    "    kid=True\n",
    "    prc=True,\n",
    ")\n",
    "\n",
    "platform_cfg = PlatformConfig(\n",
    "    verbose=True,\n",
    "    cuda=True,\n",
    "    save_cpu_ram=False,\n",
    "    compare_real_to_real=True\n",
    ")\n",
    "\n",
    "platform_manager = PlatformManager(real_images_path=os.path.join(os.getcwd(), \"original_64\"),\n",
    "                                   eval_config=eval_cfg,\n",
    "                                   platform_config=platform_cfg)\n",
    "\n",
    "platform_manager.calc_metrics()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"vgg16\" with features ['fc2_relu']\n",
      "Extracting features from input1\n",
      "Processing samples                                                             \n",
      "Extracting features from input2\n",
      "Processing samples                                                             \n",
      "Precision: 0.54721999168396\n",
      "Recall: 0.43487998843193054\n",
      "F-score: 0.4846248416075926\n"
     ]
    }
   ],
   "source": [
    "import torch_fidelity\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "metrics_dict = torch_fidelity.calculate_metrics(\n",
    "    input1=platform_manager.helper.real_images_src.get_dataset(), \n",
    "    input2=platform_manager.helper.get_generator_src(\"guidedDiffusion_IP\").get_dataset(), \n",
    "    cuda=True, \n",
    "    isc=False, \n",
    "    fid=False, \n",
    "    kid=False, \n",
    "    prc=True, \n",
    "    verbose=True,\n",
    "    save_cpu_ram=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating feature extractor \"vgg16\" with features ['fc2_relu']\n",
      "Extracting features from input1\n",
      "Processing samples                                                             \n",
      "Extracting features from input2\n",
      "Processing samples                                                             \n",
      "Precision: 0.6168400049209595\n",
      "Recall: 0.3585200011730194\n",
      "F-score: 0.4534725186722886\n"
     ]
    }
   ],
   "source": [
    "metrics_dict = torch_fidelity.calculate_metrics(\n",
    "    input1=platform_manager.helper.real_images_src.get_dataset(), \n",
    "    input2=platform_manager.helper.get_generator_src(\"diffusionStyleGAN2\").get_dataset(), \n",
    "    cuda=True, \n",
    "    isc=False, \n",
    "    fid=False, \n",
    "    kid=False, \n",
    "    prc=True, \n",
    "    verbose=True,\n",
    "    save_cpu_ram=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 64, 64, 3) size array saved into celeba64_train.npz\n"
     ]
    }
   ],
   "source": [
    "from framework.util import img_to_64\n",
    "\n",
    "img_to_64(\"D:\\Dokumente\\SoftwareDev\\MasterThesis\\GIM-evaluation\\cifar-10\\\\train\\\\train\\\\\",\n",
    "             \"D:\\Dokumente\\SoftwareDev\\MasterThesis\\GIM-evaluation\\cifar-10\\\\64res\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GIM-Eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
